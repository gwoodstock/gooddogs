{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/working_data/model_data_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[data['time_in_shelter'] > 7]['at_risk']\n",
    "X = data[data['time_in_shelter'] > 7].drop(columns=['at_risk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['age_in', 'obey', 'height_low_inches', 'height_high_inches', 'weight_low_lbs', 'weight_high_lbs']   # 82.5\n",
    "# numeric_cols = ['age_in', 'obey', 'height_low_inches', 'height_high_inches']    # no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dum = pd.concat([\n",
    "    # X[numeric_cols], \n",
    "    pd.get_dummies(X[cat_features]), \n",
    "    # pd.get_dummies(X['breed_2']),\n",
    "    pd.get_dummies(X['breed_1']),\n",
    "    # pd.get_dummies(X['primary_color'], prefix='color'), \n",
    "    pd.get_dummies(X['condition'], prefix='condition'), \n",
    "    # pd.get_dummies(X['intake_type'], prefix='intake')\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dum, y, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.540995\n",
       "0    0.459005\n",
       "Name: at_risk, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=200, min_samples_split=10, n_estimators=300,\n",
       "                       random_state=123)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300, max_depth=200, random_state=123, min_samples_split=10)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found some signal!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6570870214967237\n",
      "0.6324137931034483\n"
     ]
    }
   ],
   "source": [
    "print(rfc.score(X_train, y_train))\n",
    "print(rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found some success with the random forest classifier. Roughly 9% above baseline. Using a decision tree makes sense give the breakdown of our data, as it is mostly sparse classifiers. Regularized trees can more effectively isolate the features with signal than a linear model, even with L1 dropout.\n",
    "\n",
    "Will build a stripped version of the model for production purposes and try to improve model performance with more advanced decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Run Next](https://github.com/gwoodstock/project4/blob/main/8_modela_rfc_stripped.ipynb): Stripped Random Forest Classifier."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6aaf12f00e2accd7ab3a69f0361120d5b81b11b109d190d2913220c8ee37ccf8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
